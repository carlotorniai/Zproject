{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TO DO \n",
      "=========\n",
      "Dependencies for EC2 : Install ruby and at least the gem to get the profile.\n",
      "Write a fiel utils with just the thing i need for the web app:\n",
      "SO far : readpickle, compute_educaiton_fields (that can be adapted)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "SO i will have as a startting input just a public linkedin profile URL.\n",
      "\n",
      "Let's work with mine and try to make the workflow"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import web_utils as wu\n",
      "reload(wu)\n",
      "public_profile_url = \"http://www.linkedin.com/in/carlotorniai\"\n",
      "\n",
      "# I will need to build a feature vector out of it.\n",
      "# I will need to know the features.\n",
      "\n",
      "# Let's load the proper file\n",
      "feature_matrix = wu.readpickle('./models/full-features_no_zeros_for_classification.pkl')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_matrix.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "(1344, 5004)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's build a dict out of the columns\n",
      "features_dict = dict()\n",
      "for elem in feature_matrix.columns:\n",
      "    features_dict[elem] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(features_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "5004"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At this point i need to retrive all the info from the public profile.\n",
      "In particular skills and education.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import subprocess\n",
      "import json\n",
      "public_profile_url = \"www.linkedin.com/in/carlotorniai\"\n",
      "# Check if public profile url starts with www add http://\n",
      "if 'http://' not in public_profile_url and public_profile_url[0] == 'w':\n",
      "    public_profile_url = 'http://' + public_profile_url\n",
      "p = subprocess.Popen([\"./linkedin-scraper\",  public_profile_url], stdout=subprocess.PIPE)\n",
      "out, err = p.communicate()\n",
      "json_profile = json.loads(out)\n",
      "print json_profile.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'picture', u'first_name', u'last_name', u'name', u'title', u'skills', u'country', u'industry', u'linkedin_url', u'past_companies', u'websites', u'summary', u'languages', u'certifications', u'location', u'groups', u'recommended_visitors', u'education', u'current_companies', u'organizations']\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "skills = json_profile['skills']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now let's process the skills\n",
      "for skill in skills:\n",
      "    if skill in features_dict:\n",
      "        features_dict[skill] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in features_dict.items():\n",
      "    if v ==1:\n",
      "        print k"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Ontologies\n",
        "Python\n",
        "Ontology Engineering\n",
        "E-Learning\n",
        "Semantic Technologies\n",
        "Semantics\n",
        "Natural Language Processing\n",
        "Metadata\n",
        "Computer Science\n",
        "Algorithms\n",
        "Data Mining\n",
        "Pattern Recognition\n",
        "RDF\n",
        "Knowledge Management\n",
        "Bioinformatics\n",
        "Machine Learning\n",
        "E-learning\n",
        "Ontology Development\n",
        "Programming\n",
        "Linked Data\n",
        "OWL\n",
        "SPARQL\n",
        "Information Retrieval\n",
        "Science\n",
        "Semantic Modeling\n",
        "Java\n",
        "Data Integration\n",
        "Data Science\n",
        "Semantic Web\n",
        "Knowledge Representation\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# More complex is the education i need first to get a dict with the compute_education_fields\n",
      "# Then use the method (adapted ) get_cat_ed_features from stats "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "json_profile['education']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[{u'description': u'PhD, Informatics, Multimedia and Telecommunication',\n",
        "  u'name': u'Universit\\xe0 degli Studi di Firenze',\n",
        "  u'period': u'2004 \\u2013 2007'},\n",
        " {u'description': u'Master, Internet Engineering',\n",
        "  u'name': u'Universit\\xe0 degli Studi di Firenze',\n",
        "  u'period': u'2002 \\u2013 2003'},\n",
        " {u'description': u'Bachelor, Telecommunication Engineer',\n",
        "  u'name': u'Universit\\xe0 degli Studi di Firenze',\n",
        "  u'period': u'1991 \\u2013 1998'}]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To test if all this owrks gran a profile for an ide existing in the matrix, build the feature matrix \n",
      "# and check if they are the same.\n",
      "# Check for 2 or 3 examples\n",
      "reload(wu)\n",
      "educations = wu.compute_education_fields(json_profile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "educations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "{'bc_1': 1,\n",
        " 'bc_2': -1,\n",
        " 'mas_1': 'engineering',\n",
        " 'mas_2': -1,\n",
        " 'mba_1': -1,\n",
        " 'mba_2': -1,\n",
        " 'phd_1': 1,\n",
        " 'phd_2': -1}"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(wu)\n",
      "\n",
      "ed_features = wu.get_education_features(educations)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ed_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "{'mas_1_engineering': 1, 'other_bc_1': 1, 'other_phd_1': 1}"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if 'other_bc_1' in feature_matrix.columns:\n",
      "    print \"found\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "found\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in features_dict.items():\n",
      "    if k in ed_features:\n",
      "        features_dict[k] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in features_dict.items():\n",
      "    if v ==1:\n",
      "        print k"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "other_bc_1\n",
        "other_phd_1\n",
        "Ontologies\n",
        "Python\n",
        "Ontology Engineering\n",
        "E-Learning\n",
        "Semantic Technologies\n",
        "Semantics\n",
        "Natural Language Processing\n",
        "Metadata\n",
        "Computer Science\n",
        "Algorithms\n",
        "Data Mining\n",
        "Pattern Recognition\n",
        "RDF\n",
        "Knowledge Management\n",
        "Bioinformatics\n",
        "Machine Learning\n",
        "E-learning\n",
        "Ontology Development\n",
        "Programming\n",
        "Linked Data\n",
        "OWL\n",
        "mas_1_engineering\n",
        "SPARQL\n",
        "Information Retrieval\n",
        "Science\n",
        "Semantic Modeling\n",
        "Java\n",
        "Data Integration\n",
        "Data Science\n",
        "Semantic Web\n",
        "Knowledge Representation\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_vector = []\n",
      "for elem in feature_matrix.columns:\n",
      "    if features_dict[elem] == 1:\n",
      "        # print elem \n",
      "        feature_vector.append(1)\n",
      "    else:\n",
      "        feature_vector.append(0)\n",
      "feature_vector.count(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "33"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now I think I wil need to be classified and refrieved.. maybe and I will need probably a uniqeu identifier\n",
      "# Let's see If I can use a decision tree.."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "X = feature_vector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(wu)\n",
      "mnb = wu.readpickle('./models/NB_with_full_features_with_labels.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred = mnb.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "array([ 1.])"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cpt = mnb.predict_proba(X)\n",
      "cpt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 98,
       "text": [
        "array([[  2.41712763e-11,   9.99948073e-01,   2.18719249e-12,\n",
        "          2.21469919e-26,   5.19272040e-05]])"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_sum = cpt.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_sum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 126,
       "text": [
        "0.99999999999999689"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "relative_probability_classes = [(x/total_sum) for x in cpt[0]]\n",
      "relative_probability_classes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 127,
       "text": [
        "[2.4171276303362033e-11,\n",
        " 0.99994807276959752,\n",
        " 2.187192487353011e-12,\n",
        " 2.2146991924224908e-26,\n",
        " 5.1927204044054933e-05]"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum = 0\n",
      "for elem in relative_probability_classes:\n",
      "    print \"%.2f\" %(elem)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.00\n",
        "1.00\n",
        "0.00\n",
        "0.00\n",
        "0.00\n"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log_cpt = mnb.predict_log_proba(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log_cpt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 129,
       "text": [
        "array([[ -2.44458561e+01,  -5.19285787e-05,  -2.68484024e+01,\n",
        "         -5.90720958e+01,  -9.86566774e+00]])"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum_probs = log_cpt[0].sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum_probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 121,
       "text": [
        "-120.23207398045238"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "normalized_prob = [(x/sum_probs) for x in log_cpt[0]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "normalized_prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 123,
       "text": [
        "[0.20332225260717326,\n",
        " 4.3190287709176951e-07,\n",
        " 0.22330482603282673,\n",
        " 0.49131728225822568,\n",
        " 0.082055207198897251]"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum = 0\n",
      "for elem in normalized_prob:\n",
      "    print \"%.2f\" %(elem)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.20\n",
        "0.00\n",
        "0.22\n",
        "0.49\n",
        "0.08\n"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum_test = test_prob.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "0.9999999996766985"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below the full code for extractign features and profiles\n",
      "========="
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ok Let' write the whole function here\n",
      "import web_utils as wu\n",
      "import subprocess\n",
      "import json\n",
      "\n",
      "def extractfeatures(public_profile_url, feature_matrix, log = False):\n",
      "    ''' it takes as input an URL of a Linkedin public Profile\n",
      "    extract features. It returns the json file of the profiles and the feature vector '''\n",
      "\n",
      "    feature_vector = []\n",
      "    found_skills = False\n",
      "    found_education = False\n",
      "    \n",
      "    # './models/full-features_no_zeros_for_classification.pkl'\n",
      "    # Load the feature_matrix\n",
      "   \n",
      "    \n",
      "    # Initialize the dict for the features\n",
      "    features_dict = dict()\n",
      "    for elem in feature_matrix.columns:\n",
      "        features_dict[elem] = 0\n",
      "        \n",
      "    # Here need to hanle better all the possible errors\n",
      "    # For now just a dummy one\n",
      "    if 'http://' not in public_profile_url and public_profile_url[0] == 'w':\n",
      "        public_profile_url = 'http://' + public_profile_url\n",
      "    \n",
      "    # Retrieve the public profile\n",
      "    p = subprocess.Popen([\"./linkedin-scraper\",  public_profile_url], stdout=subprocess.PIPE)\n",
      "    out, err = p.communicate()\n",
      "    # Here handle the errors if I put a non existing profile\n",
      "    if log:\n",
      "        print \"Error\" , err\n",
      "    \n",
      "    profile = json.loads(out)\n",
      "    \n",
      "    # Check if skills and education are in the profile\n",
      "    # Otherwise Classification can't really be extracted\n",
      "    \n",
      "    if 'skills' in profile:\n",
      "        if len(profile['skills']) > 0:\n",
      "            found_skills = True\n",
      "    \n",
      "    if 'education' in profile:\n",
      "        if len(profile['education']) > 0:\n",
      "            found_education = True\n",
      "    \n",
      "    if not found_skills and not found_education:\n",
      "        print \"I can't find education and skills information in your profile\"\n",
      "        return \n",
      "    \n",
      "    # Now let's process the skills\n",
      "    for skill in skills:\n",
      "        if skill in features_dict:\n",
      "            features_dict[skill] = 1\n",
      "    \n",
      "    # Sanity check\n",
      "    if log:\n",
      "        for k, v in features_dict.items():\n",
      "            if v ==1:\n",
      "                print k\n",
      "    \n",
      "    # Get educations\n",
      "    ed_features = wu.get_education_features(educations)\n",
      "    \n",
      "    if log:\n",
      "        print ed_features\n",
      "    \n",
      "    # Add educations to the feature dict\n",
      "    for k, v in features_dict.items():\n",
      "        if k in ed_features:\n",
      "            features_dict[k] = 1\n",
      "    \n",
      "    #Sanity check\n",
      "    if log:\n",
      "        for k, v in features_dict.items():\n",
      "            if v ==1:\n",
      "                print k\n",
      "    # Build just a vector of zeroe and ones\n",
      "    for elem in feature_matrix.columns:\n",
      "        if features_dict[elem] == 1:\n",
      "            # print elem \n",
      "            feature_vector.append(1)\n",
      "        else:\n",
      "            feature_vector.append(0)\n",
      "    \n",
      "    return profile, feature_vector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import web_utils as wu\n",
      "public_profile_url = \"http://www.linkedin.com/in/carlotorniai\"\n",
      "# feature_matrix = wu.readpickle('./models/full-features_no_zeros_for_classification.pkl')\n",
      "# load the NMB classifier \n",
      "# mnb = wu.readpickle('./models/NB_with_full_features_with_labels.pkl')\n",
      "lables_dict = {0 : \"Computer Scientist\", 1 : \"Data Scientist\", 2 : \"Statistician\",\\\n",
      "                   3 : \"Business Analyst\", 4 : \"Mathematician\"}\n",
      "profile, feature_vector = wu.extractfeatures(public_profile_url, feature_matrix, log = False)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"This is the profile of %s %s\" %(profile['first_name'], profile['last_name'])\n",
      "print \"Currently %s\" %(profile['title'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "This is the profile of Carlo Torniai\n",
        "Currently Data Science fellow at Zipfian Academy\n"
       ]
      }
     ],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now Let's classify using the NMB\n",
      "class_label_key = mnb.predict(feature_vector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Based on skills and educattion your closest profile is %s \" %(lables_dict[int(class_label_key)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Based on skills and educattion your closest profile is Data Scientist \n"
       ]
      }
     ],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(wu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 183,
       "text": [
        "<module 'web_utils' from 'web_utils.py'>"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Next CLosest folks in the clusters\n",
      "reload(wu)\n",
      "# Training K_means with k = 5 with full features (I shoudl have it)\n",
      "# I need both the feature matrix and the model \n",
      "\n",
      "feature_matrix_km = wu.readpickle('./models/full-features_no_zeros_for_classification.pkl')\n",
      "km = wu.readpickle('./models/kmean_model_with_full_features_no_zeros.pkl')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Next CLosest folks in the clusters\n",
      "reload(wu)\n",
      "\n",
      "# Moreover I will need pymongo and the initializeDB\n",
      "db, collection = wu.initializeDb(\"zproject\" , \"final_full_profiles\")\n",
      "\n",
      "# All the things below can be doen ONE TIME at the boostrap of the app\n",
      "# Get top skills for the clusters \n",
      "top_features = wu.get_top_features(feature_matrix_km, km, 20)\n",
      "\n",
      "# Retrieve user_clusters and most representative users for each cluster\n",
      "users_clusters, ordered_user_clusters = wu.get_cluster_representatitve(feature_matrix_km, db , collection, km , 5)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 238
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_ds_skills = ['Data Mining', 'Machine Learning', 'R', 'Data Analysis', 'Python',\\\n",
      "                 'Statistical Modeling', 'Hadoop', 'Big Data', 'Statistics', \\\n",
      "                 'SQL', u'Predictive Analytics', 'Pig', 'Hive', 'MapReduce']\n",
      "\n",
      "closest_cluster = km.predict(feature_vector)\n",
      "\n",
      "# print top_features[str(closest_cluster[0])]\n",
      "# print ordered_user_clusters[str(closest_cluster[0])][:3]\n",
      "\n",
      "# Suggest Skills \n",
      "# Here I should just put the ones identified manually\n",
      "# suggested_skills = set(top_features[str(closest_cluster[0])] + top_ds_skills) - set(profile['skills'])\n",
      "suggested_skills = set(top_ds_skills) - set(profile['skills'])\n",
      "\n",
      "print \"We suggest, If you aren't already familiar with the following topics/tools to explore the \\\n",
      "suggested resources below\"\n",
      "# Here build a set of resources for categories:\n",
      "# Business Analysts , \n",
      "for elem in suggested_skills:\n",
      "    print \"--\" , elem\n",
      "    # Here retrieve form DB according to the predicted label\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "We suggest, If you aren't already familiar with the following topics/tools to explore the suggested resources below\n",
        "-- Data Analysis\n",
        "-- Big Data\n",
        "-- Hadoop\n",
        "-- Hive\n",
        "-- MapReduce\n",
        "-- R\n",
        "-- Statistics\n",
        "-- Statistical Modeling\n",
        "-- SQL\n",
        "-- Pig\n",
        "-- Predictive Analytics\n"
       ]
      }
     ],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.spatial.distance import pdist, cdist , squareform, euclidean\n",
      "from operator import itemgetter\n",
      "\n",
      "def get_closest_datascientists(user_feature_vector, feature_matrix, cluster_members):\n",
      "    ''' Returns , if any the closest data scientist to the user profiles '''\n",
      "    closest_ds_found = 0\n",
      "    users_in_cluster = []\n",
      "    closest_ds = []\n",
      "    for member in cluster_members:\n",
      "        member_id = member[0]\n",
      "        # Retrieve the feature vector \n",
      "        member_feature_vector = feature_matrix.loc[member_id]\n",
      "        distance = euclidean(user_feature_vector, member_feature_vector)\n",
      "        # Add the member and the distance to the list\n",
      "        value = (member, distance)\n",
      "        users_in_cluster.append(value)\n",
      "    # Computes the ordered list\n",
      "    closest_users_in_cluster = sorted(users_in_cluster,key=itemgetter(1))\n",
      "    #print closest_users_in_cluster\n",
      "    # Now until 3 are found check if there is a Data scientist in it \n",
      "    for user in closest_users_in_cluster:\n",
      "        if user[0][5]==1:\n",
      "            closest_ds.append(user)\n",
      "    return closest_ds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 255
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the closest folks with Data Science label in the cluster if any\n",
      "# Otherwise report the top \n",
      "closest_ds_in_cluster = get_closest_datascientists(X, feature_matrix_km, users_clusters[str(closest_cluster[0])])\n",
      "# print \"Found %d Close Data Scientists\" %(len(closest_ds_in_cluster))\n",
      "if len(closest_ds_in_cluster)>0:\n",
      "    print \"The following users are Data Scientists that are close to your profile:\"\n",
      "    if len(closest_ds_in_cluster)>=3:\n",
      "        num_item = 3\n",
      "    else:\n",
      "        num_item = len(closest_ds_in_cluster)\n",
      "        \n",
      "    for elem in closest_ds_in_cluster[:num_item]:\n",
      "        print elem"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 216 Close Data Scientists\n",
        "The following users are Data Scientists that are close to your profile:\n",
        "((u'fqmGyY2Ymv', u'Christian', u'Schaefer', u'http://www.linkedin.com/pub/christian-schaefer/33/660/5b7', 3.0729511179398141, 1), 5.9160797830996161)\n",
        "((u'AF2RNnOxKy', u'Michael', u'Conover', u'http://www.linkedin.com/in/michaelconover', 3.4258120471456186, 1), 5.9160797830996161)\n",
        "((u'BwQgYinJzd', u'Kapil', u'Dalwani', u'http://www.linkedin.com/in/kapildalwani', 3.6846409678348491, 1), 6.0)\n"
       ]
      }
     ],
     "prompt_number": 256
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(wu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 257,
       "text": [
        "<module 'web_utils' from 'web_utils.py'>"
       ]
      }
     ],
     "prompt_number": 257
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(wu)\n",
      "closest_ds_in_cluster = wu.get_closest_datascientists(X, feature_matrix_km, users_clusters[str(closest_cluster[0])])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 261
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Found %d Close Data Scientists\" %(len(closest_ds_in_cluster))\n",
      "if len(closest_ds_in_cluster)>0:\n",
      "    print \"The following users are Data Scientists that are close to your profile:\"\n",
      "    if len(closest_ds_in_cluster)>=3:\n",
      "        num_item = 3\n",
      "    else:\n",
      "        num_item = len(closest_ds_in_cluster)\n",
      "        \n",
      "    for elem in closest_ds_in_cluster[:num_item]:\n",
      "        # Here print if firstname and lastname aren't the same \n",
      "        # that the current user\n",
      "        if profile['last_name']!= elem [0][2]:\n",
      "            print elem[0][1], elem [0][2], elem [0][3]\n",
      "        else:\n",
      "            if profile['first_name']!= elem [0][1]:"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 216 Close Data Scientists\n",
        "The following users are Data Scientists that are close to your profile:\n",
        "Christian Schaefer http://www.linkedin.com/pub/christian-schaefer/33/660/5b7\n",
        "Michael Conover http://www.linkedin.com/in/michaelconover\n",
        "Kapil Dalwani http://www.linkedin.com/in/kapildalwani\n"
       ]
      }
     ],
     "prompt_number": 266
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}